{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83c374f-754c-460e-bfc8-368b6f445e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514bd5d6-9b23-48d2-bb29-9e47ca3f9adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>VIDEO_NAME</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Brandon Pryor</td>\n",
       "      <td>2014-01-19 00:36:25</td>\n",
       "      <td>I dont even watch it anymore i just come here ...</td>\n",
       "      <td>PSY - GANGNAM STYLE(?????) M/V</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chelsea Yun</td>\n",
       "      <td>2015-05-23 07:17:09.691</td>\n",
       "      <td>i hate rap﻿</td>\n",
       "      <td>Eminem - Love The Way You Lie ft. Rihanna</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sofia Aristizabal</td>\n",
       "      <td>2014-09-09 00:43:52</td>\n",
       "      <td>I loved, she is amazing.. OMG your eyes*_*﻿</td>\n",
       "      <td>Katy Perry - Roar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>said abdesalam</td>\n",
       "      <td>2015-05-24 07:35:13.754</td>\n",
       "      <td>song is bad﻿</td>\n",
       "      <td>Eminem - Love The Way You Lie ft. Rihanna</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>crazy girl</td>\n",
       "      <td>2015-05-23 23:26:05.305</td>\n",
       "      <td>tension⤴︎⤴︎﻿</td>\n",
       "      <td>LMFAO - Party Rock Anthem ft. Lauren Bennett, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COMMENT_ID             AUTHOR                     DATE  \\\n",
       "0           1      Brandon Pryor      2014-01-19 00:36:25   \n",
       "1           2        Chelsea Yun  2015-05-23 07:17:09.691   \n",
       "2           3  Sofia Aristizabal      2014-09-09 00:43:52   \n",
       "3           4     said abdesalam  2015-05-24 07:35:13.754   \n",
       "4           5         crazy girl  2015-05-23 23:26:05.305   \n",
       "\n",
       "                                             CONTENT  \\\n",
       "0  I dont even watch it anymore i just come here ...   \n",
       "1                                        i hate rap﻿   \n",
       "2        I loved, she is amazing.. OMG your eyes*_*﻿   \n",
       "3                                       song is bad﻿   \n",
       "4                                       tension⤴︎⤴︎﻿   \n",
       "\n",
       "                                          VIDEO_NAME  CLASS  \n",
       "0                     PSY - GANGNAM STYLE(?????) M/V      0  \n",
       "1          Eminem - Love The Way You Lie ft. Rihanna      0  \n",
       "2                                  Katy Perry - Roar      0  \n",
       "3          Eminem - Love The Way You Lie ft. Rihanna      0  \n",
       "4  LMFAO - Party Rock Anthem ft. Lauren Bennett, ...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec7ccff-6006-4562-90de-15bd7b126e31",
   "metadata": {},
   "source": [
    "Now, let's use the bert classifier. Just doing some testing first to get an  understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e90566-4c28-4e4b-9ffd-fd246834f634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2054, 1037, 3376, 2417, 3123, 102]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "encoded_X = tokenizer.encode(\"What a beautiful red rose \")\n",
    "print(encoded_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36bae200-6996-421a-9c54-b3798b88101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6469, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "king_token_id = tokenizer.convert_tokens_to_ids([\"king\"])[0]\n",
    "king_embedding = model.embeddings.word_embeddings(torch.tensor([king_token_id]))\n",
    "\n",
    "queen_token_id = tokenizer.convert_tokens_to_ids([\"queen\"])[0]\n",
    "queen_embedding = model.embeddings.word_embeddings(torch.tensor([queen_token_id]))\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=1)\n",
    "similarity = cos(king_embedding, queen_embedding)\n",
    "print(similarity[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1c6c9-8f4a-4edc-a09a-c800b0208cd9",
   "metadata": {},
   "source": [
    "The code above is some basic experimentation I did. Now let's actually process the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3bd316-0ac9-4c9f-83a9-ccdd16415a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d2dfd4c-4736-459c-b0d3-c51a7c189929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam = df[df[\"CLASS\"] == 1]\n",
    "df_ham = df[df[\"CLASS\"] == 0]\n",
    "df_spam.shape\n",
    "df_ham.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5d93f-0316-4a12-aaa1-9ed901c41876",
   "metadata": {},
   "source": [
    "710 spams, 659 non-spam emails. We want equal amount of spam and ham this time, so reduce spam to 659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f17574c5-d757-439f-9130-5c475f32d7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam_downsampled = df_spam.sample(df_ham.shape[0])\n",
    "df_spam_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17dadbc6-7121-470b-ae1a-00f16c0f04a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1318, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([df_spam_downsampled, df_ham])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1641da-bd88-4013-8672-df913ff47eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>VIDEO_NAME</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>Louis Bryant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You guys should check out this EXTRAORDINARY w...</td>\n",
       "      <td>Eminem - Love The Way You Lie ft. Rihanna</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1311</td>\n",
       "      <td>Wafence</td>\n",
       "      <td>2013-09-04 19:16:44.109</td>\n",
       "      <td>Hey Youtubers and All Music lover&amp;#39;s, Guess...</td>\n",
       "      <td>Shakira - Waka Waka</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1302</td>\n",
       "      <td>maddog1431</td>\n",
       "      <td>2014-08-12 18:38:42</td>\n",
       "      <td>Check out my covers I have a video coming out ...</td>\n",
       "      <td>Katy Perry - Roar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>410</td>\n",
       "      <td>Yeung Marvin</td>\n",
       "      <td>2014-11-12 23:56:54</td>\n",
       "      <td>Haha its so funny to see the salt of westerner...</td>\n",
       "      <td>PSY - GANGNAM STYLE(?????) M/V</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1353</td>\n",
       "      <td>Jay Stevens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COME SUBSCRIBE TO MY CHANNEL! ;-)  PLEASE!!</td>\n",
       "      <td>Eminem - Love The Way You Lie ft. Rihanna</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      COMMENT_ID        AUTHOR                     DATE  \\\n",
       "137          138  Louis Bryant                      NaN   \n",
       "1310        1311       Wafence  2013-09-04 19:16:44.109   \n",
       "1301        1302    maddog1431      2014-08-12 18:38:42   \n",
       "409          410  Yeung Marvin      2014-11-12 23:56:54   \n",
       "1352        1353   Jay Stevens                      NaN   \n",
       "\n",
       "                                                CONTENT  \\\n",
       "137   You guys should check out this EXTRAORDINARY w...   \n",
       "1310  Hey Youtubers and All Music lover&#39;s, Guess...   \n",
       "1301  Check out my covers I have a video coming out ...   \n",
       "409   Haha its so funny to see the salt of westerner...   \n",
       "1352        COME SUBSCRIBE TO MY CHANNEL! ;-)  PLEASE!!   \n",
       "\n",
       "                                     VIDEO_NAME  CLASS  \n",
       "137   Eminem - Love The Way You Lie ft. Rihanna      1  \n",
       "1310                        Shakira - Waka Waka      1  \n",
       "1301                          Katy Perry - Roar      1  \n",
       "409              PSY - GANGNAM STYLE(?????) M/V      0  \n",
       "1352  Eminem - Love The Way You Lie ft. Rihanna      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16698bd7-9715-4f1b-ad53-a3888ce4efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[\"CONTENT\"]\n",
    "Y = df2[\"CLASS\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e11d83f-6d8e-46d7-a8e5-c1d665c6de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_preprocess(texts, tokenizer, max_length=128):\n",
    "    \"\"\"\n",
    "    Tokenize input texts for BERT with padding, truncation, and attention masks.\n",
    "    \"\"\"\n",
    "    encoded = tokenizer(\n",
    "        texts.tolist(),          # Convert Pandas Series to list\n",
    "        padding=True,            # Pad to the longest sequence\n",
    "        truncation=True,         # Truncate to max_length\n",
    "        max_length=max_length,   # Set maximum sequence length\n",
    "        return_tensors=\"tf\"      # Return TensorFlow tensors\n",
    "    )\n",
    "    return encoded\n",
    "\n",
    "# 4. Custom Encoding Function\n",
    "def bert_encode(encoded_inputs, bert_model):\n",
    "    \"\"\"\n",
    "    Extract pooled output ([CLS] token embedding) from BERT.\n",
    "    \"\"\"\n",
    "    outputs = bert_model(encoded_inputs)\n",
    "    pooled_output = outputs.pooler_output  # Shape: (batch_size, hidden_size)\n",
    "    return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b86cf50-e944-4d7a-8dc5-7faff1131a19",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Op type not registered 'CaseFoldUTF8' in binary running on users-MBP-5. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:3061\u001b[0m, in \u001b[0;36mGraph.op_def_for_type\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   3060\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3061\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m]\n\u001b[1;32m   3062\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CaseFoldUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[1;32m      2\u001b[0m text_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstring)\n\u001b[0;32m----> 3\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mKerasLayer(\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m encoder_inputs \u001b[38;5;241m=\u001b[39m preprocessor(text_input)\n\u001b[1;32m      6\u001b[0m encoder \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mKerasLayer(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-12-h-768-a-12/2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow_hub/keras_layer.py:165\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m data_structures\u001b[38;5;241m.\u001b[39mNoDependency(\n\u001b[1;32m    162\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func \u001b[38;5;241m=\u001b[39m load_module(handle, tags, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_options)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hub_module_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Update with the defaults when using legacy TF1 Hub format.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow_hub/keras_layer.py:467\u001b[0m, in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# Expected before TF2.4.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m       set_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[0;32m--> 467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module_v2\u001b[38;5;241m.\u001b[39mload(handle, tags\u001b[38;5;241m=\u001b[39mtags, options\u001b[38;5;241m=\u001b[39mset_load_options)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow_hub/module_v2.py:126\u001b[0m, in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    123\u001b[0m   obj \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload_v2(\n\u001b[1;32m    124\u001b[0m       module_path, tags\u001b[38;5;241m=\u001b[39mtags, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m   obj \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload_v2(module_path, tags\u001b[38;5;241m=\u001b[39mtags)\n\u001b[1;32m    127\u001b[0m obj\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m is_hub_module_v1  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/load.py:912\u001b[0m, in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[1;32m    911\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[0;32m--> 912\u001b[0m result \u001b[38;5;241m=\u001b[39m load_partial(export_dir, \u001b[38;5;28;01mNone\u001b[39;00m, tags, options)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/load.py:1042\u001b[0m, in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[1;32m   1041\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1042\u001b[0m     loader \u001b[38;5;241m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[1;32m   1043\u001b[0m                     ckpt_options, options, filters)\n\u001b[1;32m   1044\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1046\u001b[0m         \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1047\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/load.py:161\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proto \u001b[38;5;241m=\u001b[39m object_graph_proto\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_dir \u001b[38;5;241m=\u001b[39m export_dir\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 161\u001b[0m     function_deserialization\u001b[38;5;241m.\u001b[39mload_function_def_library(\n\u001b[1;32m    162\u001b[0m         library\u001b[38;5;241m=\u001b[39mmeta_graph\u001b[38;5;241m.\u001b[39mgraph_def\u001b[38;5;241m.\u001b[39mlibrary,\n\u001b[1;32m    163\u001b[0m         saved_object_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proto,\n\u001b[1;32m    164\u001b[0m         wrapper_function\u001b[38;5;241m=\u001b[39m_WrapperFunction))\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# captures.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restored_concrete_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/function_deserialization.py:456\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[0;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# There is no need to copy all functions into the function def graph. It\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# leads to a O(n^2) increase of memory when importing functions and the\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# extra function definitions are a no-op since they already imported as a\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# function before and passed in explicitly (due to the topologic sort\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# import).\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m--> 456\u001b[0m   func_graph \u001b[38;5;241m=\u001b[39m function_def_lib\u001b[38;5;241m.\u001b[39mfunction_def_to_graph(\n\u001b[1;32m    457\u001b[0m       fdef,\n\u001b[1;32m    458\u001b[0m       structured_input_signature\u001b[38;5;241m=\u001b[39mstructured_input_signature,\n\u001b[1;32m    459\u001b[0m       structured_outputs\u001b[38;5;241m=\u001b[39mstructured_outputs)\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# custom gradients)\u001b[39;00m\n\u001b[1;32m    462\u001b[0m _restore_gradient_functions(func_graph, renamed_functions, loaded_gradients)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/framework/function_def_to_graph.py:91\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec, include_library_functions)\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m         input_shapes\u001b[38;5;241m.\u001b[39mappend(input_shape)\n\u001b[0;32m---> 91\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[38;5;241m=\u001b[39m function_def_to_graph_def(\n\u001b[1;32m     92\u001b[0m     fdef, input_shapes, include_library_functions\u001b[38;5;241m=\u001b[39minclude_library_functions\n\u001b[1;32m     93\u001b[0m )\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m     96\u001b[0m   \u001b[38;5;66;03m# Add all function nodes to the graph.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m   importer\u001b[38;5;241m.\u001b[39mimport_graph_def_for_function(\n\u001b[1;32m     98\u001b[0m       graph_def, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, propagate_device_spec\u001b[38;5;241m=\u001b[39mpropagate_device_spec)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/framework/function_def_to_graph.py:330\u001b[0m, in \u001b[0;36mfunction_def_to_graph_def\u001b[0;34m(fdef, input_shapes, include_library_functions)\u001b[0m\n\u001b[1;32m    328\u001b[0m       graph_def\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mgradient\u001b[38;5;241m.\u001b[39mextend([grad_def])\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m   op_def \u001b[38;5;241m=\u001b[39m default_graph\u001b[38;5;241m.\u001b[39mop_def_for_type(node_def\u001b[38;5;241m.\u001b[39mop)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m op_def\u001b[38;5;241m.\u001b[39mattr:\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m attr\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:3064\u001b[0m, in \u001b[0;36mGraph.op_def_for_type\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   3061\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m]\n\u001b[1;32m   3062\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   3063\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m op_def_pb2\u001b[38;5;241m.\u001b[39mOpDef\u001b[38;5;241m.\u001b[39mFromString(\n\u001b[0;32m-> 3064\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_for_type(\u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m   3065\u001b[0m   )\n\u001b[1;32m   3066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on users-MBP-5. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed."
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessor = hub.KerasLayer(\n",
    "    \"https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\")\n",
    "encoder_inputs = preprocessor(text_input)\n",
    "encoder = hub.KerasLayer(\n",
    "    \"https://www.kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-12-h-768-a-12/2\",\n",
    "    trainable=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb03e6-7aa2-4008-9948-b611b576dd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
